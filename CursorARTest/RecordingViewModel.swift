import Foundation
import AVFoundation
import AVKit

enum Mode {
    case transcribe
    case stream
}

class RecordingViewModel: NSObject, ObservableObject, AVAudioRecorderDelegate {
    @Published var outputs: [String] = []
    @Published var isRecording = false
    @Published var isUploading = false
    @Published var mode: Mode = .transcribe
    @Published var sessionID: String? = nil

    private var recorder: AVAudioRecorder?
    private var tempFileURL: URL?

    // WebSocket & Stream
    private var webSocketTask: URLSessionWebSocketTask?
    // AVCaptureSession å·²ç§»é™¤
    // private var session: AVCaptureSession?
    private var audioSession: AVAudioSession?
    // AVAudioEngine ç›¸é—œ
    private var audioEngine: AVAudioEngine?
    private var inputFormat: AVAudioFormat?
    private var outputFormat: AVAudioFormat?

    func toggleRecording() {
        isRecording ? stopRecording() : startRecording()
    }

    private func startRecording() {
        if mode == .stream {
            startStreaming()
        } else {
            startTranscribeRecording()
        }
    }

    private func stopRecording() {
        if mode == .stream {
            stopStreaming()
        } else {
            stopTranscribeRecording()
        }
    }

    // MARK: - Transcribe æ¨¡å¼ï¼ˆåŸå§‹éŒ„éŸ³å„²å­˜ä¸¦ä¸Šå‚³ï¼‰
    private func startTranscribeRecording() {
        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatLinearPCM),
            AVSampleRateKey: 16000,
            AVNumberOfChannelsKey: 1,
            AVLinearPCMBitDepthKey: 16,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]

        let tempDir = FileManager.default.temporaryDirectory
        let filename = UUID().uuidString + ".wav"
        tempFileURL = tempDir.appendingPathComponent(filename)

        do {
            recorder = try AVAudioRecorder(url: tempFileURL!, settings: settings)
            recorder?.delegate = self
            recorder?.record()
            isRecording = true
            outputs = ["ğŸ™ï¸ é–‹å§‹éŒ„éŸ³..."]
        } catch {
            outputs = ["âŒ éŒ„éŸ³å¤±æ•—ï¼š\(error.localizedDescription)"]
        }
    }

    private func stopTranscribeRecording() {
        recorder?.stop()
        isRecording = false
        outputs.append("ğŸ›‘ éŒ„éŸ³çµæŸï¼Œæº–å‚™ä¸Šå‚³...")

        if let url = tempFileURL {
            uploadAudio(fileURL: url)
        }
    }
    
    private var audioConverter: AVAudioConverter?
    private let targetSampleRate: Double = 16000
    private var targetFormat: AVAudioFormat?

    // MARK: - Stream æ¨¡å¼ï¼ˆç”¨ AVAudioEngine å‚³é€ 16bit PCM åˆ° WebSocketï¼‰
    private func startStreaming() {
        outputs = ["ğŸ™ï¸ é–‹å§‹å»ºç«‹éŸ³è¨Šä¸²æµ..."]

        var wsURLString = Config.API.stream
        if let sessionID = sessionID, !sessionID.isEmpty {
            wsURLString += "?session=\(sessionID)"
        }
        let url = URL(string: wsURLString)!
        webSocketTask = URLSession.shared.webSocketTask(with: url)
        webSocketTask?.resume()

        audioSession = AVAudioSession.sharedInstance()
        do {
            try audioSession?.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker])
            try audioSession?.setPreferredSampleRate(16000)
            try audioSession?.setActive(true)
        } catch {
            outputs.append("âŒ åˆå§‹åŒ–å¤±æ•—ï¼š\(error.localizedDescription)")
            return
        }

        audioEngine = AVAudioEngine()
        guard let audioEngine = audioEngine else { return }
        let inputNode = audioEngine.inputNode
        let hwFormat = inputNode.inputFormat(forBus: 0) // ç¡¬é«”æ ¼å¼
        let targetFormat = AVAudioFormat(commonFormat: .pcmFormatInt16, sampleRate: 16000, channels: 1, interleaved: true)!

        let converter = AVAudioConverter(from: hwFormat, to: targetFormat)!

        inputNode.removeTap(onBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: hwFormat) { [weak self] (buffer, time) in
            guard let self = self else { return }
            let convertedBuffer = AVAudioPCMBuffer(pcmFormat: targetFormat, frameCapacity: AVAudioFrameCount(targetFormat.sampleRate) * buffer.frameLength / AVAudioFrameCount(hwFormat.sampleRate))!
            var error: NSError?
            let inputBlock: AVAudioConverterInputBlock = { _, outStatus in
                outStatus.pointee = .haveData
                return buffer
            }
            converter.convert(to: convertedBuffer, error: &error, withInputFrom: inputBlock)
            let data = Data(bytes: convertedBuffer.int16ChannelData![0], count: Int(convertedBuffer.frameLength * 2))
            self.webSocketTask?.send(.data(data)) { error in
                if let error = error {
                    DispatchQueue.main.async {
                        self.outputs.append("âŒ å‚³é€å¤±æ•—ï¼š\(error.localizedDescription)")
                    }
                }
            }
        }

        do {
            try audioEngine.start()
            isRecording = true
            outputs.append("ğŸŒ WebSocket å·²é€£ç·šï¼Œé–‹å§‹ä¸²æµ...")
        } catch {
            outputs.append("âŒ AudioEngine å•Ÿå‹•å¤±æ•—ï¼š\(error.localizedDescription)")
        }

        receiveMessages()
    }

    private func stopStreaming() {
        isRecording = false
        audioEngine?.inputNode.removeTap(onBus: 0)
        audioEngine?.stop()
        audioEngine = nil
        webSocketTask?.send(.string("stop")) { _ in }
        webSocketTask?.cancel(with: .goingAway, reason: nil)
        outputs.append("ğŸ›‘ å·²åœæ­¢ä¸²æµéŒ„éŸ³")
    }

    // MARK: - WebSocket æ¥æ”¶è¨Šæ¯
    private func receiveMessages() {
        webSocketTask?.receive { [weak self] result in
            guard let self = self else { return }
            switch result {
            case .success(let message):
                switch message {
                case .data(let data):
                    self.handleWebSocketData(data)
                case .string(let text):
                    if let data = text.data(using: .utf8) {
                        self.handleWebSocketData(data)
                    } else {
                        self.outputs.append("âš ï¸ å­—ä¸²è½‰è³‡æ–™å¤±æ•—")
                    }
                @unknown default:
                    self.outputs.append("âš ï¸ æœªçŸ¥çš„ WebSocket è¨Šæ¯æ ¼å¼")
                }
                self.receiveMessages() // æŒçºŒæ¥æ”¶

            case .failure(let error):
                DispatchQueue.main.async {
                    self.outputs.append("âŒ æ¥æ”¶å¤±æ•—ï¼š\(error.localizedDescription)")
                }
            }
        }
    }

    private func handleWebSocketData(_ data: Data) {
        do {
            // è§£ææ•´ä»½ JSON ç‚º [String: Any]
            if let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
               let speakers = json["speakers"] as? [[String: Any]] {

                DispatchQueue.main.async {
                    for speakerInfo in speakers {
                        let speaker = speakerInfo["speaker"] as? String ?? "æœªçŸ¥"
                        let text = speakerInfo["text"] as? String ?? ""
                        let line = "\(speaker)ï¼š\(text)"
                        self.outputs.append(line)
                    }
                }

            } else {
                // å¦‚æœ speakers æ¬„ä½ä¸å­˜åœ¨ï¼Œå°å‡ºåŸå§‹ JSON å­—ä¸²
                if let rawString = String(data: data, encoding: .utf8) {
                    print("ğŸ“¦ å›å‚³æ ¼å¼ä¸å« speakersï¼š\n\(rawString)")
                    DispatchQueue.main.async {
                        self.outputs.append("ğŸ“© \(rawString)")
                    }
                }
            }

        } catch {
            DispatchQueue.main.async {
                self.outputs.append("âŒ JSON è§£æéŒ¯èª¤ï¼š\(error.localizedDescription)")
            }
        }
    }



    // MARK: - Transcribe ä¸Šå‚³éŸ³è¨Š
    func uploadAudio(fileURL: URL) {
        isUploading = true
        outputs.append("â« ä¸Šå‚³ä¸­...")

        var request = URLRequest(url: URL(string: Config.API.transcribe)!)
        request.httpMethod = "POST"

        let boundary = UUID().uuidString
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")

        var body = Data()

        body.append("--\(boundary)\r\n")
        body.append("Content-Disposition: form-data; name=\"file\"; filename=\"audio.wav\"\r\n")
        body.append("Content-Type: audio/wav\r\n\r\n")
        body.append((try? Data(contentsOf: fileURL)) ?? Data())
        body.append("\r\n--\(boundary)--\r\n")

        URLSession.shared.uploadTask(with: request, from: body) { data, response, error in
            DispatchQueue.main.async {
                self.isUploading = false
            }

            if let error = error {
                DispatchQueue.main.async {
                    self.outputs.append("âŒ ä¸Šå‚³éŒ¯èª¤ï¼š\(error.localizedDescription)")
                }
                return
            }

            guard let data = data else { return }
            if let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
               let pretty = json["pretty"] as? [[String: Any]] {
                DispatchQueue.main.async {
                    for item in pretty {
                        let line = "\(item["speaker"] ?? "æœªçŸ¥")ï¼š\(item["text"] ?? "")"
                        self.outputs.append(line)
                    }
                }
            } else {
                DispatchQueue.main.async {
                    self.outputs.append("âš ï¸ å›å‚³æ ¼å¼è§£æå¤±æ•—")
                }
            }
        }.resume()
    }
}

// MARK: - Data Append Helper
fileprivate extension Data {
    mutating func append(_ string: String) {
        if let data = string.data(using: .utf8) {
            append(data)
        }
    }
}

import AVFoundation

extension AVAudioPCMBuffer {
    convenience init?(from sampleBuffer: CMSampleBuffer) {
        guard let formatDesc = CMSampleBufferGetFormatDescription(sampleBuffer),
              let asbd = CMAudioFormatDescriptionGetStreamBasicDescription(formatDesc) else { return nil }
        let format = AVAudioFormat(streamDescription: asbd)
        let numSamples = CMSampleBufferGetNumSamples(sampleBuffer)
        self.init(pcmFormat: format!, frameCapacity: AVAudioFrameCount(numSamples))
        self.frameLength = AVAudioFrameCount(numSamples)
        guard let blockBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) else { return nil }
        var length = 0
        var dataPointer: UnsafeMutablePointer<Int8>?
        CMBlockBufferGetDataPointer(blockBuffer, atOffset: 0, lengthAtOffsetOut: nil, totalLengthOut: &length, dataPointerOut: &dataPointer)
        if let dataPointer = dataPointer {
            switch format!.commonFormat {
            case .pcmFormatFloat32:
                memcpy(self.floatChannelData![0], dataPointer, length)
            case .pcmFormatInt16:
                memcpy(self.int16ChannelData![0], dataPointer, length)
            default:
                return nil
            }
        }
    }
}
